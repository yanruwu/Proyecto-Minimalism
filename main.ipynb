{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import pandas as pd\n",
    "from pytubefix.contrib.search import Search\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from time import sleep\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from itertools import islice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_links(url, base_url, class_name):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    cat_list = soup.find('div', class_ = class_name)\n",
    "    links = [base_url+a.get('href') for a in cat_list.findAll('a')]\n",
    "    cats_title = [a.text.strip() for a in cat_list.findAll('a')]\n",
    "    return zip(links, cats_title)\n",
    "\n",
    "def get_item_df(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    #* Título\n",
    "    title = soup.find('h1').get_text(strip=True) if soup.find('h1') else None\n",
    "    #* Opiniones\n",
    "    opinion = soup.find('span', class_='stamped-badge-caption')\n",
    "    op_count = opinion.get('data-reviews') if opinion else np.nan\n",
    "    op_rating = opinion.get('data-rating') if opinion else np.nan\n",
    "    #* Precio\n",
    "    price = soup.find('span', class_ = 'current-price theme-money').text.replace('€', '')\n",
    "    #*Color\n",
    "    color_options = []\n",
    "    color_container = soup.find('div', class_='option-selector--swatch')\n",
    "    if color_container:\n",
    "        color_options = [span.get_text(strip=True) for span in color_container.find_all('span') if span.get_text(strip=True)]\n",
    "    if len(color_options) == 0:\n",
    "        color_options = np.nan\n",
    "    #* Tallas\n",
    "    size_options = []\n",
    "    for tag in soup.find_all(['span', 'button']):\n",
    "        text = tag.get_text(strip=True)\n",
    "        # Filtra los tamaños esperados\n",
    "        if text in ['XS', 'S', 'M', 'L', 'XL', 'XXL']:\n",
    "            size_options.append(text)\n",
    "    if len(size_options) == 0:\n",
    "        size_options = np.nan\n",
    "\n",
    "    #* Impacto\n",
    "    try:\n",
    "        impact = soup.find(\"summary\", class_ = 'cc-accordion-item__title', string = 'Impacto ambiental').find_parent().text \n",
    "        co2 = re.search(r\"(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s*kg de emisiones de CO2\", impact)\n",
    "        co2 = co2.group(1).replace(\",\", \".\") if co2 else np.nan\n",
    "\n",
    "        agua = re.search(r\"(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s*litros de agua\", impact)\n",
    "        agua = agua.group(1).replace(\",\", \".\") if agua else np.nan\n",
    "\n",
    "        energia = re.search(r\"(\\d{1,3}(?:\\.\\d{3})*(?:,\\d+)?)\\s*kWh de energía\", impact)\n",
    "        energia = energia.group(1).replace(\",\", \".\") if energia else np.nan\n",
    "    except:\n",
    "        co2, agua, energia = [np.nan]*3\n",
    "    #! Producto total\n",
    "    product_details = {\n",
    "    'Nombre': title,\n",
    "    'Opiniones': op_count,\n",
    "    'Rating': op_rating,\n",
    "    'Precio': price,\n",
    "    'Opciones de color': color_options,\n",
    "    'Tamaños': size_options,\n",
    "    'CO2' : co2,\n",
    "    'Agua': agua,\n",
    "    \"Energia\": energia\n",
    "    }\n",
    "    df_producto = pd.DataFrame([product_details])\n",
    "    return df_producto\n",
    "def get_prod_links(url, base_url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    productos = soup.find('div', class_='filters-adjacent collection-listing')\n",
    "    productos_links = [base_url+a.find('a').get('href') for a in productos.findAll('div', class_ = 'product-info')]\n",
    "    return productos_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scrapeando\n",
      "Hombre\n",
      "Scrapeando\n",
      "Mujer\n",
      "Scrapeando\n",
      "Niño\n",
      "Scrapeando\n",
      "Mochilas\n"
     ]
    }
   ],
   "source": [
    "cat = 'navigation__tier-1-container'\n",
    "url_hombre = 'https://minimalismbrand.com/collections/ropa-minimalism'\n",
    "base_minimalism = 'https://minimalismbrand.com'\n",
    "subcat_cl = 'gallery gallery--height-fixed gallery--grid-4'\n",
    "subsubcat_cl = 'collection-links-wrapper'\n",
    "\n",
    "df_productos = pd.DataFrame()\n",
    "categorias = get_category_links(url = base_minimalism, class_name=cat, base_url = base_minimalism)\n",
    "# print(categorias)\n",
    "for cat_link, cat_name in islice(categorias, 0,4):\n",
    "    print(\"Scrapeando\")\n",
    "    print(cat_name)\n",
    "    # print(\"Superlink:\")\n",
    "    # print(cat_link)\n",
    "    try:\n",
    "        subcats = get_category_links(url = cat_link, base_url=base_minimalism, class_name=subcat_cl)\n",
    "    except:\n",
    "        # print(\"No hay subcategorías\")\n",
    "        # subcats = [cat_link]\n",
    "        # subcat_name = np.nan\n",
    "        subcats = zip([cat_link], [np.nan])\n",
    "    for subcat_link, subcat_name in subcats:\n",
    "        # print(subcat_name)\n",
    "        if subcat_name == 'Jerseis':\n",
    "            if cat_name == 'Hombre':\n",
    "                subcat_link = 'https://minimalismbrand.com/collections/sweater-men'\n",
    "            elif cat_name == 'Mujer':\n",
    "                subcat_link = 'https://minimalismbrand.com/collections/sweater-women'\n",
    "        # print(\"Link principal\")\n",
    "        # print(link)\n",
    "        try:\n",
    "            subsubcats= get_category_links(url = subcat_link, base_url=base_minimalism, class_name=subsubcat_cl)\n",
    "            # print(\"Sublinks:\")\n",
    "            # print(subsubcats)\n",
    "            # print()\n",
    "        except Exception as e:\n",
    "            subsubcats = zip([subcat_link],[np.nan])\n",
    "            # print(e)\n",
    "            pass\n",
    "        for subsubcat_link, subsubcat_name in subsubcats:\n",
    "            # print(subsubcat_name)\n",
    "            try:\n",
    "                prod_links = get_prod_links(url = subsubcat_link, base_url=base_minimalism)\n",
    "            except:\n",
    "                prod_links = [subsubcat_link]\n",
    "            for prod_link in prod_links:\n",
    "                df_elemento = get_item_df(prod_link)\n",
    "                df_elemento[\"categoria\"] = cat_name\n",
    "                df_elemento[\"subcategoria\"] = subcat_name\n",
    "                df_elemento[\"subsubcategoria\"] = subsubcat_name\n",
    "                df_productos = pd.concat([df_productos,df_elemento])\n",
    "df_productos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos[df_productos.drop(columns=[\"Opciones de color\",\"Tamaños\", \"categoria\"]).duplicated(keep=False)].to_csv(\"datos/duplicados_mini.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "dupl_prod_id = df_productos[df_productos.drop(columns=[\"Opciones de color\",\"Tamaños\"]).duplicated()].index\n",
    "df_productos.drop(index=dupl_prod_id, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_productos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "unisex_mini_ids = df_productos[df_productos.drop(columns=[\"Opciones de color\",\"Tamaños\",\"categoria\"]).duplicated(keep=False)].index\n",
    "df_productos.loc[unisex_mini_ids, \"categoria\"] = \"Unisex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicated_unisex_id = df_productos[df_productos.drop(columns=[\"Opciones de color\",\"Tamaños\"]).duplicated()].index\n",
    "df_productos.drop(index=duplicated_unisex_id, inplace=True)\n",
    "df_productos.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Nombre', 'Opiniones', 'Rating', 'Precio', 'Opciones de color',\n",
       "       'Tamaños', 'CO2', 'Agua', 'Energia', 'categoria', 'subcategoria',\n",
       "       'subsubcategoria'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[col for col in df_productos.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_productos.reset_index().drop(columns=[\"Opciones de color\", \"Tamaños\"]).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url = 'https://ecoalf.com/collections/sports-woman')\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "sleep(3)\n",
    "women_html = driver.find_element(By.CSS_SELECTOR, \"ul.grid.negative-margin.product-grid\").get_attribute(\"innerHTML\")\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()\n",
    "\n",
    "driver.get(url = 'https://ecoalf.com/collections/sports-man')\n",
    "driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "sleep(3)\n",
    "men_html = driver.find_element(By.CSS_SELECTOR, \"ul.grid.negative-margin.product-grid\").get_attribute(\"innerHTML\")\n",
    "driver.quit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_soup = BeautifulSoup(women_html, \"html.parser\")\n",
    "men_soup = BeautifulSoup(men_html, \"html.parser\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "women_prods = [\"https://ecoalf.com\"+e.find('a').get('href') for e in women_soup.findAll('li')]\n",
    "men_prods = [\"https://ecoalf.com\"+e.find('a').get('href') for e in men_soup.findAll('li')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:52<00:00,  1.51it/s]\n",
      "100%|██████████| 93/93 [00:58<00:00,  1.59it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_product_info(url):\n",
    "    response = requests.get(url)\n",
    "    soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "    litros_agua = np.nan\n",
    "    kg_co2 = np.nan\n",
    "\n",
    "    #* Impacto\n",
    "    reports = soup.find_all('div', class_='accordion__content-report')\n",
    "    # Variables para almacenar los resultados\n",
    "    litros_agua = None\n",
    "    co2_ahorro = None\n",
    "\n",
    "    for report in reports:\n",
    "        # Busca si el texto contiene 'litros de agua' o 'emisiones CO2' y extrae los valores\n",
    "        texto = report.get_text()\n",
    "        # print(texto)\n",
    "        if 'litros de agua utilizados' in texto:\n",
    "            # print(texto)\n",
    "            agua = float(report.find('strong').text.strip().replace(',','.'))\n",
    "        elif 'kg CO2 eq generados' in texto:\n",
    "            # print(texto)\n",
    "            co2 = float(report.find('strong').text.strip().replace(',','.'))  # Extrae el ahorro de CO2\n",
    "\n",
    "    #* Nombre\n",
    "    name = soup.find('h1', 'product__title h4').text.strip().capitalize()\n",
    "    #* Precio\n",
    "    price = soup.find('div', class_ = 'price__regular price-item price-item--regular').text.strip().replace('€','')\n",
    "    #* Colores\n",
    "    colors = [c.text.strip().capitalize() for c in soup.find('div', 'product__colors rte').findAll('a')] if soup.find('div', 'product__colors rte') else np.nan\n",
    "    #* Tallas\n",
    "    sizes = [s.get('data-get-size') for s in soup.find('fieldset', class_ = 'js product-form__input input--talla').findAll('label')] if soup.find('fieldset', class_ = 'js product-form__input input--talla') else np.nan\n",
    "\n",
    "    product_info = {\"Nombre\" : name,\n",
    "                    \"Precio\" : price,\n",
    "                    \"Colores\" : colors,\n",
    "                    \"Tallas\" : sizes}\n",
    "    return pd.DataFrame([product_info])\n",
    "\n",
    "df_ecoalf_men = pd.DataFrame()\n",
    "df_ecoalf_women = pd.DataFrame()\n",
    "try:\n",
    "    for link in tqdm(men_prods):\n",
    "        df_ecoalf_men = pd.concat([df_ecoalf_men,get_product_info(link)])\n",
    "    for link in tqdm(women_prods):\n",
    "        df_ecoalf_women = pd.concat([df_ecoalf_women,get_product_info(link)])\n",
    "    df_ecoalf_men[\"Categoria\"] = \"Hombre\"\n",
    "    df_ecoalf_women[\"Categoria\"] = \"Mujer\"\n",
    "    df_ecoalf_men[\"Link\"] = men_prods\n",
    "    df_ecoalf_women[\"Link\"] = women_prods\n",
    "except Exception as e:\n",
    "    print(link)\n",
    "    print(e)\n",
    "\n",
    "df_ecoalf = pd.concat([df_ecoalf_men, df_ecoalf_women]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unisex_ids = df_ecoalf[df_ecoalf[\"Link\"].duplicated(keep=False)].index\n",
    "df_ecoalf.loc[unisex_ids, \"Categoria\"] = \"Unisex\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nombre</th>\n",
       "      <th>Categoria</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Top bombay naranja</td>\n",
       "      <td>Hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pantalones cortos barcelona cactus</td>\n",
       "      <td>Hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Camiseta zurich negra</td>\n",
       "      <td>Hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chaqueta boulders negra</td>\n",
       "      <td>Hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Top bombay negro</td>\n",
       "      <td>Hombre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>167</th>\n",
       "      <td>Botella sports de acero inoxidable bronson azul</td>\n",
       "      <td>Unisex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>168</th>\n",
       "      <td>Botella sports de acero inoxidable bronson blanca</td>\n",
       "      <td>Unisex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>169</th>\n",
       "      <td>Sudadera unisex orlando verde</td>\n",
       "      <td>Unisex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>Sudadera unisex madagascar azul marino</td>\n",
       "      <td>Unisex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>Sudadera unisex madagascar blanca</td>\n",
       "      <td>Unisex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>172 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Nombre Categoria\n",
       "0                                   Top bombay naranja    Hombre\n",
       "1                   Pantalones cortos barcelona cactus    Hombre\n",
       "2                                Camiseta zurich negra    Hombre\n",
       "3                              Chaqueta boulders negra    Hombre\n",
       "4                                     Top bombay negro    Hombre\n",
       "..                                                 ...       ...\n",
       "167    Botella sports de acero inoxidable bronson azul    Unisex\n",
       "168  Botella sports de acero inoxidable bronson blanca    Unisex\n",
       "169                      Sudadera unisex orlando verde    Unisex\n",
       "170             Sudadera unisex madagascar azul marino    Unisex\n",
       "171                  Sudadera unisex madagascar blanca    Unisex\n",
       "\n",
       "[172 rows x 2 columns]"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ecoalf[[\"Nombre\", \"Categoria\"]]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
